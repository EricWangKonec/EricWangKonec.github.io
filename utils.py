#!/usr/bin/env python3
"""
å·¥å…·æ¨¡å—ï¼šå¤„ç†APIè¯·æ±‚ã€æ–‡ä»¶ä¸‹è½½ã€ç›®å½•åˆ›å»ºç­‰åŠŸèƒ½
"""

import os
import json
import requests
import re
from datetime import datetime, timedelta
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def create_daily_directory(date=None):
    """
    æ ¹æ®æ—¥æœŸåˆ›å»ºç›®å½•ç»“æ„ ./YYYY/MM/DD
    Args:
        date: datetimeå¯¹è±¡ï¼Œé»˜è®¤ä¸ºä»Šå¤©
    Returns:
        str: åˆ›å»ºçš„ç›®å½•è·¯å¾„
    """
    if date is None:
        date = datetime.now()
    
    # æ ¼å¼åŒ–æ—¥æœŸè·¯å¾„
    year = date.strftime('%Y')
    month = date.strftime('%m') 
    day = date.strftime('%d')
    
    # åˆ›å»ºç›®å½•è·¯å¾„
    dir_path = Path(f"./{year}/{month}/{day}")
    dir_path.mkdir(parents=True, exist_ok=True)
    
    print(f"âœ… åˆ›å»ºç›®å½•: {dir_path}")
    return str(dir_path)

def fetch_notion_versions():
    """
    ä»Notion APIè·å–ç‰ˆæœ¬ä¿¡æ¯
    Returns:
        dict: ç‰ˆæœ¬æ•°æ®
    """
    token = os.getenv('VERSION_INFO_NOTION_API')
    database_id = os.getenv('NOTION_DATABASE_ID')
    
    if not token or not database_id:
        print("âš ï¸ è­¦å‘Š: æœªé…ç½®Notion API tokenæˆ–æ•°æ®åº“ID")
        return None
    
    url = f"https://api.notion.com/v1/databases/{database_id}/query"
    
    headers = {
        'Content-Type': 'application/json',
        'Notion-Version': '2022-06-28',
        'Authorization': f'Bearer {token}'
    }
    
    body = {
        "filter": {
            "property": "ç‰ˆæœ¬å·",
            "title": {
                "is_not_empty": True
            }
        },
        "sorts": [
            {
                "property": "Date",
                "direction": "descending"
            }
        ]
    }
    
    try:
        print("ğŸ”„ æ­£åœ¨ä»Notionè·å–ç‰ˆæœ¬ä¿¡æ¯...")
        response = requests.post(url, headers=headers, json=body)
        response.raise_for_status()
        
        data = response.json()
        print(f"âœ… æˆåŠŸè·å– {len(data.get('results', []))} æ¡ç‰ˆæœ¬è®°å½•")
        return parse_notion_data(data)
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Notion APIè¯·æ±‚å¤±è´¥: {e}")
        return None

def parse_notion_data(notion_data):
    """
    è§£æNotion APIè¿”å›çš„æ•°æ®ä¸ºæ ‡å‡†æ ¼å¼ï¼Œå¹¶è¿‡æ»¤ä¸Šä¸ªæœˆ1å·è‡³ä»Šçš„æ•°æ®
    Args:
        notion_data: Notion APIè¿”å›çš„åŸå§‹æ•°æ®
    Returns:
        dict: æ ‡å‡†åŒ–çš„ç‰ˆæœ¬æ•°æ®
    """
    releases = []
    
    # è®¡ç®—ä¸Šä¸ªæœˆ1å·çš„æ—¥æœŸ
    today = datetime.now()
    if today.month == 1:
        last_month_first = datetime(today.year - 1, 12, 1)
    else:
        last_month_first = datetime(today.year, today.month - 1, 1)
    
    print(f"ğŸ“… æ•°æ®è¿‡æ»¤èŒƒå›´: {last_month_first.strftime('%Y-%m-%d')} è‡³ä»Š")
    
    for item in notion_data.get('results', []):
        properties = item.get('properties', {})
        
        # æå–ç‰ˆæœ¬å·
        version_prop = properties.get('ç‰ˆæœ¬å·', {})
        version = ""
        if version_prop.get('title'):
            version = version_prop['title'][0].get('plain_text', '')
        
        # æå–æ—¥æœŸ
        date_prop = properties.get('Date', {})
        date = ""
        if date_prop.get('date'):
            date = date_prop['date'].get('start', '')
        
        # æ—¥æœŸè¿‡æ»¤ï¼šåªä¿ç•™ä¸Šä¸ªæœˆ1å·è‡³ä»Šçš„æ•°æ®
        if date:
            try:
                record_date = datetime.strptime(date, '%Y-%m-%d')
                if record_date < last_month_first:
                    continue  # è·³è¿‡è¿‡æ—©çš„æ•°æ®
            except ValueError:
                print(f"âš ï¸ æ—¥æœŸæ ¼å¼é”™è¯¯: {date}")
                continue
        
        # æå–ç±»å‹
        type_prop = properties.get('Type', {})
        release_type = "main"
        if type_prop.get('select'):
            type_name = type_prop['select'].get('name', '')
            # å…ˆæ£€æŸ¥æ›´å…·ä½“çš„ç±»å‹
            if "åˆ†æ”¯ç‰ˆæœ¬å¼€å§‹" in type_name or "å¼€å§‹" in type_name:
                release_type = "branch-start"
            elif "åˆ†æ”¯åˆå¹¶" in type_name or "åˆå¹¶" in type_name or "å¹¶å…¥" in type_name or "å›ä¸»çº¿" in type_name or "æ ¸å…¥ä¸»çº¿" in type_name:
                release_type = "branch-merge"
            elif "åˆ†æ”¯ç‰ˆæœ¬" in type_name or "åˆ†æ”¯" in type_name:
                release_type = "branch"
            
        
        # æå–çŠ¶æ€
        status_prop = properties.get('Status', {})
        environment = "ç”Ÿäº§ç¯å¢ƒ"
        
        if version and date:
            releases.append({
                "version": version,
                "date": date,
                "type": release_type,
                "environment": environment,
                "note": type_prop.get('select', {}).get('name', '') if type_prop.get('select') else ""
            })
    
    print(f"âœ… è¿‡æ»¤åä¿ç•™ {len(releases)} æ¡ç‰ˆæœ¬è®°å½•")
    return {"releases": releases}

def download_external_resource(url, local_path):
    """
    ä¸‹è½½å¤–éƒ¨èµ„æºåˆ°æœ¬åœ°
    Args:
        url: èµ„æºURL
        local_path: æœ¬åœ°ä¿å­˜è·¯å¾„
    Returns:
        bool: æ˜¯å¦ä¸‹è½½æˆåŠŸ
    """
    try:
        print(f"ğŸ”„ æ­£åœ¨ä¸‹è½½: {url}")
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        
        with open(local_path, 'wb') as f:
            f.write(response.content)
        
        print(f"âœ… ä¸‹è½½å®Œæˆ: {local_path}")
        return True
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥ {url}: {e}")
        return False

def load_config_json(config_path):
    """
    åŠ è½½æœ¬åœ°JSONé…ç½®æ–‡ä»¶
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    Returns:
        dict: é…ç½®æ•°æ®
    """
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"âš ï¸ æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ {config_path}: {e}")
        return {}

def save_daily_data(data, filename, date=None):
    """
    ä¿å­˜æ•°æ®åˆ°å½“æ—¥ç›®å½•
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        filename: æ–‡ä»¶å
        date: æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    daily_dir = create_daily_directory(date)
    file_path = os.path.join(daily_dir, filename)
    
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ•°æ®å·²ä¿å­˜: {file_path}")
    return file_path

def download_bug_resources(daily_dir):
    """
    ä¸‹è½½Bugç›¸å…³çš„å›¾ç‰‡èµ„æºåˆ°å½“æ—¥ç›®å½•
    Args:
        daily_dir: å½“æ—¥ç›®å½•è·¯å¾„
    Returns:
        dict: æœ¬åœ°å›¾ç‰‡è·¯å¾„
    """
    images_dir = os.path.join(daily_dir, "images")
    os.makedirs(images_dir, exist_ok=True)
    
    # å›¾ç‰‡URLé…ç½®
    image_urls = {
        'priority_chart': os.getenv('PRIORITY_CHART_URL'),
        'variation_chart': os.getenv('BUG_VARIATION_CHART_URL'),
        'modules_chart': os.getenv('MODULES_CHART_URL'),
        'priority_history_chart': os.getenv('PRIORITY_HISTORY_CHART_URL'),
        'weekly_analysis_chart': os.getenv('WEEKLY_ANALYSIS_CHART_URL')
    }
    
    local_paths = {}
    
    for key, url in image_urls.items():
        if url:
            local_path = os.path.join(images_dir, f"{key}.png")
            if download_external_resource(url, local_path):
                local_paths[key] = local_path
                print(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {key}")
            else:
                # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œä½¿ç”¨åŸURL
                local_paths[key] = url
                print(f"âš ï¸ å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œä½¿ç”¨åŸURL: {key}")
        else:
            print(f"âš ï¸ æœªé…ç½®å›¾ç‰‡URL: {key}")
    
    return local_paths

def download_bug_data(daily_dir):
    """
    ä¸‹è½½Bugæ•°æ®æ–‡ä»¶åˆ°å½“æ—¥ç›®å½•
    Args:
        daily_dir: å½“æ—¥ç›®å½•è·¯å¾„
    Returns:
        str: æœ¬åœ°æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸‹è½½å¤±è´¥è¿”å›None
    """
    bug_data_url = os.getenv('BUG_DATA_URL')
    if not bug_data_url:
        return None
    
    local_path = os.path.join(daily_dir, "bug_data.md")
    
    if download_external_resource(bug_data_url, local_path):
        return local_path
    return None

def parse_bug_data(markdown_content):
    """
    è§£æBugæ•°æ®markdownæ–‡ä»¶ï¼Œæå–ç»Ÿè®¡ä¿¡æ¯
    Args:
        markdown_content: markdownæ–‡ä»¶å†…å®¹
    Returns:
        dict: Bugç»Ÿè®¡ä¿¡æ¯
    """
    bug_stats = {
        'monthly_new': 0,
        'monthly_closed': 0,
        'total_valid': 0,
        'in_review': 0
    }
    
    try:
        # æå–æœ¬æœˆæ–°æŠ¥å’Œå…³é—­æ•°é‡
        monthly_pattern = r'æœ¬æœˆæ€»è®¡æ–°æŠ¥\*\*(\d+)\*\*ä¸ªBug.*?æ€»è®¡å…³é—­\*\*(\d+)\*\*ä¸ªBug'
        monthly_match = re.search(monthly_pattern, markdown_content)
        if monthly_match:
            bug_stats['monthly_new'] = int(monthly_match.group(1))
            bug_stats['monthly_closed'] = int(monthly_match.group(2))
            print(f"ğŸ“Š æå–åˆ°æœˆåº¦æ•°æ®: æ–°æŠ¥{bug_stats['monthly_new']}, å…³é—­{bug_stats['monthly_closed']}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æœˆåº¦Bugæ•°æ®")
        
        # æå–æœ‰æ•ˆBugé€è§†å›¾æ€»æ•°ï¼ˆåŒ…å«In Reviewï¼‰
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªè¡¨æ ¼çš„æ€»æ•°è¡Œï¼Œéœ€è¦åŒ¹é…è¡¨æ ¼æœ€åä¸€åˆ—çš„æ•°å­—
        valid_section = re.search(r'### æœ‰æ•ˆBugé€è§†å›¾.*?(?=###|$)', markdown_content, re.DOTALL)
        total_with_review = 0
        if valid_section:
            valid_content = valid_section.group(0)
            # åœ¨è¿™ä¸ªéƒ¨åˆ†æŸ¥æ‰¾æ€»æ•°è¡Œï¼ŒåŒ¹é…è¡¨æ ¼ä¸­æœ€åä¸€åˆ—çš„æ•°å­—
            total_line = re.search(r'\| æ€»æ•°.*?\|\s*\d+\s*\|\s*\d+\s*\|\s*\d+\s*\|\s*\d+\s*\|\s*(\d+)\s*\|', valid_content)
            if total_line:
                total_with_review = int(total_line.group(1))
                print(f"ğŸ“Š æœ‰æ•ˆBugæ€»æ•°(å«In Review): {total_with_review}")
            else:
                print("âš ï¸ åœ¨æœ‰æ•ˆBugé€è§†å›¾ä¸­æœªæ‰¾åˆ°æ€»æ•°è¡Œ")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆBugé€è§†å›¾éƒ¨åˆ†")
        
        # æå–ä¸å«In Reviewçš„æœ‰æ•ˆBugé€è§†å›¾æ€»æ•°
        no_review_section = re.search(r'### ä¸å«In Reviewçš„æœ‰æ•ˆBugé€è§†å›¾.*?(?=###|$)', markdown_content, re.DOTALL)
        if no_review_section:
            no_review_content = no_review_section.group(0)
            # åœ¨è¿™ä¸ªéƒ¨åˆ†æŸ¥æ‰¾æ€»æ•°è¡Œï¼ŒåŒ¹é…è¡¨æ ¼ä¸­æœ€åä¸€åˆ—çš„æ•°å­—
            total_line = re.search(r'\| æ€»æ•°.*?\|\s*\d+\s*\|\s*\d+\s*\|\s*\d+\s*\|\s*\d+\s*\|\s*(\d+)\s*\|', no_review_content)
            if total_line:
                total_without_review = int(total_line.group(1))
                bug_stats['total_valid'] = total_without_review
                
                # è®¡ç®—In Reviewæ•°é‡
                if total_with_review > 0:
                    bug_stats['in_review'] = total_with_review - total_without_review
                
                print(f"ğŸ“Š ä¸å«In Review Bugæ€»æ•°: {bug_stats['total_valid']}")
                print(f"ğŸ“Š In Review Bugæ•°é‡: {bug_stats['in_review']}")
            else:
                print("âš ï¸ åœ¨ä¸å«In Reviewé€è§†å›¾ä¸­æœªæ‰¾åˆ°æ€»æ•°è¡Œ")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ä¸å«In Reviewçš„Bugé€è§†å›¾éƒ¨åˆ†")
        
    except Exception as e:
        print(f"âš ï¸ è§£æBugæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    return bug_stats

def get_bug_stats_from_data(daily_dir):
    """
    ä»ä¸‹è½½çš„Bugæ•°æ®ä¸­æå–ç»Ÿè®¡ä¿¡æ¯
    Args:
        daily_dir: å½“æ—¥ç›®å½•è·¯å¾„
    Returns:
        dict: Bugç»Ÿè®¡ä¿¡æ¯
    """
    bug_data_path = os.path.join(daily_dir, "bug_data.md")
    
    if os.path.exists(bug_data_path):
        try:
            with open(bug_data_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return parse_bug_data(content)
        except Exception as e:
            print(f"âš ï¸ è¯»å–Bugæ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
    
    # å¦‚æœæ²¡æœ‰æ•°æ®æ–‡ä»¶æˆ–è¯»å–å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
    return {
        'monthly_new': 0,
        'monthly_closed': 0,
        'total_valid': 0,
        'in_review': 0
    }

def load_watch_dog_data():
    """
    åŠ è½½æ‰€æœ‰watch dogç›‘æ§æ•°æ®
    Returns:
        dict: æ‰€æœ‰ç›‘æ§å¯¹è±¡çš„æ•°æ®ï¼Œkeyä¸ºobjectIdï¼Œvalueä¸ºç›‘æ§å†å²
    """
    watch_dog_dir = "config/watch_dog_data"
    watch_dog_data = {}
    
    if not os.path.exists(watch_dog_dir):
        print(f"âš ï¸ ç›‘æ§æ•°æ®ç›®å½•ä¸å­˜åœ¨: {watch_dog_dir}")
        return watch_dog_data
    
    try:
        # éå†æ‰€æœ‰JSONæ–‡ä»¶
        for filename in os.listdir(watch_dog_dir):
            if filename.endswith('.json'):
                file_path = os.path.join(watch_dog_dir, filename)
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    object_id = data.get('objectId')
                    if object_id:
                        watch_dog_data[object_id] = data
                        object_name = data.get('objectName', object_id)
                        print(f"âœ… åŠ è½½ç›‘æ§æ•°æ®: {object_name} ({len(data.get('history', []))} æ¡è®°å½•)")
    except Exception as e:
        print(f"âŒ åŠ è½½ç›‘æ§æ•°æ®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    return watch_dog_data

def calculate_daily_stability(watch_dog_data, start_date, end_date):
    """
    è®¡ç®—æ¯å¤©çš„ç¨³å®šæ€§æ•°æ®
    Args:
        watch_dog_data: ç›‘æ§æ•°æ®
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
    Returns:
        dict: æ¯å¤©çš„ç¨³å®šæ€§æ•°æ®
    """
    daily_stats = {}
    current_date = start_date
    
    while current_date <= end_date:
        date_str = current_date.strftime('%Y-%m-%d')
        daily_stats[date_str] = {}
        
        # éå†æ‰€æœ‰ç›‘æ§å¯¹è±¡
        for object_id, obj_data in watch_dog_data.items():
            history = obj_data.get('history', [])
            
            # ç»Ÿè®¡å½“å¤©çš„çŠ¶æ€
            total_checks = 0
            online_checks = 0
            has_data = False
            
            for record in history:
                # è§£æè®°å½•æ—¶é—´
                try:
                    record_time = datetime.fromisoformat(record['timestamp'].replace('Z', '+00:00'))
                    record_date = record_time.date()
                    
                    # å¦‚æœæ˜¯å½“å¤©çš„è®°å½•
                    if record_date == current_date.date():
                        has_data = True
                        total_checks += 1
                        if record.get('status') == 'online':
                            online_checks += 1
                except Exception as e:
                    print(f"âš ï¸ è§£ææ—¶é—´æˆ³å¤±è´¥: {record.get('timestamp')}")
                    continue
            
            # è®¡ç®—ç¨³å®šæ€§ç™¾åˆ†æ¯”
            if has_data:
                stability_percent = (online_checks / total_checks * 100) if total_checks > 0 else 0
                daily_stats[date_str][object_id] = {
                    'stability': stability_percent,
                    'total_checks': total_checks,
                    'online_checks': online_checks,
                    'has_data': True
                }
            else:
                daily_stats[date_str][object_id] = {
                    'stability': None,
                    'total_checks': 0,
                    'online_checks': 0,
                    'has_data': False
                }
        
        current_date += timedelta(days=1)
    
    return daily_stats